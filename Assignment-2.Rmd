---
title: "Assignment 2"
author: "Brock Wilson"
date: "5/17/2021"
output: html_document
---

```{R}
library(pacman)

p_load(data.table, dtplyr, dplyr, ggplot2, knitr, kableExtra, fixest, modelsummary, broom)
```

## 1. How does recreational marijuana legalization affect crime.

Several states have legalized marijuana for recreational use. The goal in this study, is to estimate whether recreational marijuana legalization has increased violent crime, based on data from the supplemental homicides reports (SHR) (shr.csv file).

Start with micro level data from SHR. In the dataset, I would you like to keep only murders involving 3 or fewer victims to avoid mass shootings or other crimes (terrorism events like 9/11). So keep only the murders with additional_victim_count of 3 or fewer. Aggregate up to the state by year level. Then merge with population data from the state_pop.csv file. Create a variable murder_pop which is murders/(pop/100000). The average murder rate in the US is around 5 recently. Inspect the time series for each state. You’ll find you should drop 3 state_fips regions due to under-reporting/missing data (you find which 3).

The following states legalized recreational marijuana recently.

Colorado – 2014 

Washington -2014 

Oregon – 2015 

Alaska – 2015 

Nevada - 2017

```{R clean}

# Reading data
shr = fread("data/shr.csv")
state_pop = fread("data/statepop.csv")

# Removing murders with more than 3 victims and those without FIPS codes
shr_final = shr[shr$additional_victim_count <= 2 & !is.na(fips_state_code),]

# Aggregating murders to state, year level
murder_rates = 
  shr_final[,
      .(victim_count = .N), 
      by = .(fips_state_code,year)
    ]
setnames(murder_rates, old = "fips_state_code", new = "state_fips")

# Merging with state population data 
state_pop_murder = 
  merge(
    state_pop[year < 2018],
    murder_rates, 
    by = c("state_fips","year"), 
    all.x = TRUE
  )

# Calculating murder_pop
state_pop_murder[, murder_pop := victim_count/(pop/100000)]

# Checking to see if murder_pop is ~5 on avg "recently"
ggplot(
  data = state_pop_murder[,
            .(avg_murder_rate = mean(murder_pop, na.rm = TRUE)), 
            by = "year"
          ],
  aes(x= year, y = avg_murder_rate)) +
  geom_line(color = "blue") +
 # geom_hline(yintercept = 5, linetype = "dashed")+
  theme_classic() +
  labs(title = "Average Murder Rate in the US",
       x= "Year",y="Avg Murder Rate (Victims/(Pop/100K))")
  

# Looking for missing data
state_pop_murder[is.na(murder_pop), .(num_na = .N), by = state] %>%
  .[num_na > 0] %>% 
  kable(col.names = c("State","Years of Missing Data")) %>%
  kable_styling(full_width = FALSE)

# Checking Alabama
ggplot(data = state_pop_murder[state_fips == 1], aes(x= year, y = murder_pop)) +
  geom_line(color = "blue") +
  theme_classic() +
  labs(title = "Murder Rate in Alabama",
       x= "Year",y="Murder Rate (Victims/(Pop/100K))")

# DC and Florida missing lots of data, Alabama reporting almost nothing after 2010
state_pop_murder_final = state_pop_murder[!(state_fips %in% c(1, 11, 12)), ]

```


```{r, eval = FALSE, echo = FALSE}
# DPLYR Version

shr_final = tibble(shr_final)

murder_rates = shr_final %>%
  group_by(fips_state_code, year) %>%
  summarise(victim_count = sum(additional_victim_count) + n())

colnames(murder_rates)[1] = "state_fips"

# Loading State Pop


colnames(state_pop)[6] = "state_fips"

# Merge data

state_pop_murder = state_pop %>%
  left_join(murder_rates, by = c("state_fips", "year"))

state_pop_murder$murder_pop = state_pop_murder$victim_count/(state_pop_murder$pop/100000)

# Inspecting for NAs/Underreporting

state_pop_murder %>%
  group_by(state_fips) %>%
  summarise(sumNA = sum(is.na(murder_pop))) %>%
  arrange(-sumNA)

# We have 2000-2020 data; this suggests that State 12 is missing all of its data (Florida)

# State 11 (D.C.) is missing a significant amount of data

state_pop_murder %>%
  group_by(state_fips) %>%
  summarise(meanMurder = mean(murder_pop, na.rm = TRUE)) %>%
  arrange(-meanMurder)

# Need to find one more state

ggplot(data = state_pop_murder, aes(x = year, y = murder_pop, color = state)) +
  geom_line()

# State 1 (Alabama) is most likely misreporting its murder rate: there is a huge discontinuous drop in the rate

state_pop_murder = data.table(state_pop_murder)

state_pop_murder_final = state_pop_murder[!(state_fips %in% c(1, 11, 12)), ]
```

### A. 

Create a dummy variable that indicates whether recreational marijuana is available within a state. Now run a regression with log(murder_pop) on the left. On the right hand side, control for state fixed effects, year fixed effects, and the recreational marijuana dummy. What is the coefficient, and upper and lower bounds. Does marijuana contribute to reefer madness as suggested by Alex Berenson in his recent book?

#### SOLUTION

The 95% confidence interval for the effect of recreational marijuana legalization on murder rate is (`r mj_coef_lb`,`r mj_coef_ub`). This indicates that legalization does not contribute to "reefer madness".


```{R}

# Creating dummy variable for recreational marijuana
state_pop_murder_final[,
   mj_legal := ifelse(
                   (year>=2015 & state == "OREGON") |
                   (year>=2014 & state == "WASHINGTON")|
                   (year>=2014 & state == "COLORADO")|
                   (year>=2015 & state == "ALASKA") |
                   (year>=2017 & state == "NEVADA"),
                  1, 0)
]

# Regressions 
reg1 = feols(
  fml = log(murder_pop) ~ mj_legal | state_fips + year,
  data = state_pop_murder_final
)

modelsummary(reg1)

# 95% confidence interval on coefficient 
mj_coef_ub = round(reg1$coefficients[1] + 1.96*reg1$se[1], digits = 3)
mj_coef_lb = round(reg1$coefficients[1] - 1.96*reg1$se[1], digits = 3)

```


### B. 

Now I want you to collapse your data to 3 regions. Colorado, Washington, and the rest of the country. Create a connected line plot with murder on the y-axis and year on the x- axis. Create a vertical line marking 2014. What broadly happens to average murder rates in Colorado and Washington, the first legalizers? What happens in the rest of the country? Do the trends in the Colorado and Washington match those in the rest of the country?

#### SOLUTION

The average murder rate in Colorado and Washington increases significantly in 2014 (Washington less so than Colorado). The rest of the country also has a large increase in the average murder rate in 2014. The trends in Colorado and Washington seem to follow the average murder rate closely, the only exception is that Colorado had a large spike in murders in 2004.

```{R}

# Creating 3 regions 
state_pop_murder_final[,
  region := ifelse(!(state %in% c("COLORADO","WASHINGTON")), "Rest of Country", state)
]

# Aggregating data by region 
region_pop_murder = 
  state_pop_murder_final[,
    .(tot_victim_count = sum(victim_count),
      tot_pop = sum(pop)),
    by = .(region,year)
  ] %>%
  .[,
    .(region, year, avg_murder_pop = tot_victim_count/(tot_pop/100000))
  ]

ggplot(data = region_pop_murder, aes(x = year, y = avg_murder_pop)) +
  geom_line(aes(color = region)) + 
  geom_vline(xintercept = 2014, linetype = "dashed")+
  theme_classic()


```

### C. 

Now use the state by year data again. Drop California, Oregon, Nevada, and Alaska (they legalized early, but not enough for post treatment data). Use a synthetic control approach to estimate the effect of marijuana legalization for both Colorado, and Washington. Match on the lagged murder rate per 100,000 for each year 2000, 2001, 2002, etc. through 2013. How does the murder rate in Colorado and Washington compare to its synthetic control average for 2014-2017?

#### SOLUTION

For Colorado, the synthetic version suggests that there is a larger increase in murder rates that Colorado avoided. For Washington, 

```{R, eval = FALSE}
# Great paper on syn control: https://economics.mit.edu/files/17847
# Using Synthetic Controls: Feasibility, Data Requirements, and Methodological Aspects
p_load(Synth)

# Dropping Cali, Oregon, Nevada, Alaska
state_pop_murder_synthetic = state_pop_murder_final[!(state_fips %in% c(6, 41, 32, 2))]

lagged_pop_murder = 
  state_pop_murder_final[,
    .(state_fips, murder_pop, year = year + 1)
  ]

state_pop_murder_synthetic =
  state_pop_murder_synthetic %>%
  merge(
    setnames(lagged_pop_murder, old = "murder_pop", new = "lagged_murder_pop"),
    by = c("state_fips","year"),
    all.x = TRUE
  )


synthcontrol = function(state_fips_treated, plot = FALSE){


# Dataprep 
dataprep = dataprep(
  foo = state_pop_murder_synthetic, # first input is our data
  predictors = c("lagged_murder_pop"), # identify our predictor variables
  predictors.op = "mean", # operation to be performed on the predictor variables for when we form our X_1 and X_0 matrices.
  time.predictors.prior = c(2001:2013), # pre-intervention window
  dependent = "murder_pop", # outcome variable
  unit.variable = "state_fips", # identify our id variable
  unit.names.variable = "state", # identify our name variable
  time.variable = "year", # identify our time period variable
  treatment.identifier = state_fips_treated, # integer that indicates the id variable value for our treatment unit
  controls.identifier =  unique(state_pop_murder_synthetic[!(state_fips %in% c(8,53,state_fips_treated)), state_fips]), # vector that indicates the id variable values for the donor pool
  time.optimize.ssr = c(2001:2014), # identify the time period you want to optimize over to find the W*. Includes pre-treatment period and the treatment year.
  time.plot = c(2001:2017) # periods over which results are to be plotted with Synth's plot functions
)

# Now we have our data ready in the form of a list. We have all the matrices we need to run synth()
# Our output from the synth() function will be a list that includes our optimal weight matrix W*

synth_out_treated = dataprep %>% synth(verbose = FALSE)

# From here, we can plot the treatment variable and the synthetic control using Synth's plot function.
# The variable tr.intake is an optional variable if you want a dashed vertical line where the intervention takes place.

if(plot){
  synth_out_treated %>% path.plot(dataprep.res = dataprep, tr.intake = 2014)
}
  
# Finally, we can construct our synthetic control variable if we wanted to conduct difference-in-difference analysis on it to estimate the treatment effect.

synth_control_treated = dataprep$Y0plot %*% synth_out_treated$solution.w

# Pre Treatment Error

preerror = mean((as.vector(synth_control_treated[1:13]) - as.vector(state_pop_murder_synthetic[state_fips==state_fips_treated & year > 2000 & year < 2014, murder_pop]))^2)

# Post Treatment Error

posterror = mean((as.vector(synth_control_treated[14:17]) - as.vector(state_pop_murder_synthetic[state_fips==state_fips_treated & year > 2013 & year < 2018, murder_pop]))^2)

return(data.frame(state_fips_treated, preerror, posterror))

}

synthcontrol(8, TRUE)

synthcontrol(53, TRUE)

```

### D. 

Use randomization inference to conduct hypothesis testing. To do so, reestimate the synthetic control approach for each state not treated excluding the two treatment states (and the other later adopting states). Estimate the mean squared error (MSE) for the placebo states, and for the treated states, both before and after recreational marijuana legalization. Now generate a ratio of postMSE/preMSE. How does CO and Washington compare to the distribution. This is your empirical p-value. Can you reject the $H_0$ that marijuana legalization did not increase crime? Why or why not?

#### SOLUTION

We fail to reject the null that marijuana did not increase crime with p values of `r co_pval` for Colorado and `r wa_pval` for Washington. This is because the ratio of PostMSE/PreMSE is low and that implies that crime did not spike post treatment. Altogether this suggests that marijuana legalization does not increase murder rates.

```{r part d}
p_load(purrr)

output = map_dfr(unique(state_pop_murder_synthetic[, state_fips]), synthcontrol)

output$ratio = output$posterror/output$preerror

output = tibble(output)

output %<>%
  arrange(-ratio) %>%
  mutate(rnk = row_number())

output = data.table(output)

# Colorado Empirical P Value
co_pval = output[state_fips_treated == 8, rnk]/(nrow(output)-1)

# Washington Empirical P Value
wa_pval = output[state_fips_treated == 53, rnk]/(nrow(output)-1)
```


## 2. Quantile Regressions

Reopen the dataset you already downloaded for replication 1, LATE_BETTER_THAN_NEVER.csv. Now make a histogram as you did before for the distribution of individual treatment effects. Make sure you put vertical lines at the 5th percentile of treatment effects, the median, and the 95 percentile of treatment effects.

Now I want you to estimate quantile treatment effects. You can either do this on your own, or use the QTE package. https://cran.r-project.org/web/packages/qte/vignettes/R- QTEsWrapper.pdf

Estimate QTE’s for every percentile from the 1 percentile to the 99th percentile. Do QTE’s allow you to recover the distribution of individual treatment effects?

#### SOLUTION

No, the QTE's do not allow you to recover the distribution of individual treatment effects; they return the average treatment effect over the distribution of outcomes. The individual treatment effects are not recoverable since we must know the joint distribution of Y1 and Y0. In the histogram, we are able to recover each individual's treatment effect and then find the 1st and 99th percentile of effects. However when we estimate the QTE, there is an adhoc assumption on the joint distribution of Y1 and Y0 to calculate the outcomes.

```{R}
bltn = read.csv("data/Better_Late_Than_Never.csv")

bltn = data.table(bltn)

ggplot(data = bltn, aes(x = T)) +
  geom_histogram(binwidth = 0.1) +
  geom_vline(xintercept = quantile(bltn$T, c(0.05)), color = "red", linetype = "dashed")  + 
  geom_vline(xintercept = quantile(bltn$T, c(0.95)), color = "red", linetype = "dashed") +
  geom_vline(xintercept = quantile(bltn$T, c(0.5)), color = "red")
 
p_load(qte)

ite = ci.qtet(formla = y ~ D, data = bltn, probs = seq(0.01,0.99,0.01))

ggqte(ite)
```

